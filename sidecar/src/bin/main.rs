use std::collections::HashMap;

use llm_client::{
    clients::{
        anthropic::AnthropicClient,
        types::{LLMClient, LLMClientCompletionRequest, LLMClientMessage, LLMType},
    },
    provider::{AnthropicAPIKey, LLMProviderAPIKeys},
};
use sidecar::chunking::languages::TSLanguageParsing;

#[tokio::main]
async fn main() {
    let fs_file_path = "/Users/skcd/scratch/ide/src/vs/workbench/browser/layout.ts".to_owned();
    // load the file contents
    let fs_file_contents = std::fs::read_to_string(fs_file_path.to_owned()).unwrap();

    let ts_language_parsing = TSLanguageParsing::init();
    let parsed_ts_file =
        ts_language_parsing.chunk_file(&fs_file_path, &fs_file_contents, None, None);
    let _id_span_mapping = parsed_ts_file
        .to_vec()
        .into_iter()
        .enumerate()
        .map(|(idx, span)| (idx, (span.start, span.end)))
        .collect::<HashMap<usize, (usize, usize)>>();
    parsed_ts_file.iter().enumerate().for_each(|(idx, span)| {
        println!("ID: {}, {}-{}", idx, span.start, span.end);
    });
    let user_instruction = r#"Sure! Here's the code with comments added to each case:
```typescript
switch (part) {
    case Parts.TITLEBAR_PART:
        // Check if the title bar part is visible in the workbench grid
        return this.workbenchGrid.isViewVisible(this.titleBarPartView);
    case Parts.SIDEBAR_PART:
        // Check if the sidebar part is not hidden based on the runtime state
        return !this.stateModel.getRuntimeValue(LayoutStateKeys.SIDEBAR_HIDDEN);
    case Parts.PANEL_PART:
        // Check if the panel part is not hidden based on the runtime state
        return !this.stateModel.getRuntimeValue(LayoutStateKeys.PANEL_HIDDEN);
    case Parts.AUXILIARYBAR_PART:
        // Check if the auxiliary bar part is not hidden based on the runtime state
        return !this.stateModel.getRuntimeValue(LayoutStateKeys.AUXILIARYBAR_HIDDEN);
    case Parts.STATUSBAR_PART:
        // Check if the status bar part is not hidden based on the runtime state
        return !this.stateModel.getRuntimeValue(LayoutStateKeys.STATUSBAR_HIDDEN);
    case Parts.ACTIVITYBAR_PART:
        // Check if the activity bar part is not hidden based on the runtime state
        return !this.stateModel.getRuntimeValue(LayoutStateKeys.ACTIVITYBAR_HIDDEN);
    case Parts.EDITOR_PART:
        // Check if the editor part is not hidden based on the runtime state
        return !this.stateModel.getRuntimeValue(LayoutStateKeys.EDITOR_HIDDEN);
    case Parts.BANNER_PART:
        // Check if the banner part is visible in the workbench grid
        return this.workbenchGrid.isViewVisible(this.bannerPartView);
    default:
        // Any other part cannot be hidden
        return false;
}
```
The comments provide a brief explanation of what each case is checking based on the part passed to the isVisible method."#.to_owned();
    // now we create the spans in the format of LLMClientMessage
    // and then we send them to the LLMClient
    let spans_content = parsed_ts_file
        .to_vec()
        .into_iter()
        .enumerate()
        .filter_map(|(idx, span)| match span.data {
            Some(data) => Some(
                format!(
                    r#"<section>
<id>
{idx}
</id>
<content>
{data}
</content>
</section>"#
                )
                .to_owned(),
            ),
            None => None,
        })
        .collect::<Vec<String>>()
        .join("\n");
    let user_instruction_llm_message = LLMClientMessage::user(
        format!(
            r#"<code_section>
{spans_content}
</code_section>

<instruction>
{user_instruction}
</instruction>

First give a brief reasoning for your answer and then print the ranking
    "#
        )
        .to_owned(),
    );
    let anthropic_client = AnthropicClient::new();
    let anthropic_api_key = "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".to_owned();
    let api_key = LLMProviderAPIKeys::Anthropic(AnthropicAPIKey::new(anthropic_api_key));
    let (sender, mut _receiver) = tokio::sync::mpsc::unbounded_channel();

    let messages = vec![
            LLMClientMessage::system(r#"You are an expert at ranking the code snippets which are most relevant to the message provided by the user.
You will be provided code sections in <code_section> tags along with their id in <id> and the content in <content> in the following format:
<code_section>
<section>
<id>
1
</id>
<content>console.log('hello world');</content>
</section>
... more sections here
</code_section>

The user will give you a message which has been generated by another Large Language Model, and it will contain one or more code blocks in the <instruction> section.

Your goal is to rank all the sections based on their relevance to the message. The sections with the highest relevance should be ranked first. The output should be a list of section ids in the order of their relevance in the following format:
<ranking>
<id>
1
</id>
... more ids
</ranking>

The end goal is to find the code sections which are most relevant to the user instruction because the code block present in the <instruction> section of the user message has to be applied to one or more sections in the <code_section> section.

As an example take the following example:
<code_section>
<section>
<id>
1
</id>
<content>
def add(a, b):
    return a + b
</content>
</section>
<section>
<id>
2
</id>
<content>
def subtract(a, b):
    return a - b
</content>
</section>
</code_section>

The instruction is:
<instruction>
Yes, we can add logs to the add function like this:
```python
def add(a, b):
    print('Adding', a, 'and', b)
    return a + b
```
</instruction>

Your output should be:
<ranking>
<id>
1
</id>
<id>
2
</id>
</ranking>

The code section 1 is most important because that contains the add function.
    "#.to_owned()),
            user_instruction_llm_message,
            // LLMClientMessage::assistant("<ranking>".to_owned())
        ];

    // now generate the messages required for testing this out
    println!("{:?}", messages);
    let request = LLMClientCompletionRequest::from_messages(messages, LLMType::ClaudeSonnet)
        .set_max_tokens(4096);
    let completion_result = anthropic_client
        .stream_completion(api_key, request, sender)
        .await;
    println!("{:?}", &completion_result);
    let completion_result = completion_result.unwrap();
    let id_ranking = completion_result
        .lines()
        .into_iter()
        .map(|line| line.to_owned())
        .take_while(|line| line.contains("</ranking>") == false)
        .filter(|line| !line.is_empty())
        .collect::<Vec<String>>();
    println!("{:?}", id_ranking);
    // now all the id ranking look like <id>{num}</id> and we have to grab the num part
    let id_ranking = id_ranking
        .into_iter()
        .map(|line| {
            line.replace("<id>", "")
                .replace("</id>", "")
                .parse::<usize>()
                .unwrap()
        })
        .collect::<Vec<usize>>();
    println!("{:?}", id_ranking);

    // let id_ranking_final = vec![
    //     135, 136, 137, 134, 133, 132, 131, 130, 129, 128, 127, 126, 125, 124, 123, 122, 121, 120,
    //     119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102,
    //     101, 100, 99, 98, 97, 96, 95, 94, 93, 92, 91, 90, 89, 88, 87, 86, 85, 84, 83, 82, 81, 80,
    //     79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 65, 64, 63, 62, 61, 60, 59, 58, 57,
    //     56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34,
    //     33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11,
    //     10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0,
    // ];
    // id_ranking_final.into_iter().for_each(|idx| {
    //     let range = id_span_mapping.get(&idx).unwrap();
    //     println!("{} - {}", range.0, range.1);
    // });
    // now we want to grab the span lines using this
}
